"""
HDF5ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""
import h5py
import numpy as np
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional
import json


class HDF5Writer:
    """HDF5ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¯ãƒ©ã‚¹"""

    # Tickãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®šç¾©
    TICK_DTYPE = [
        ('time', 'i8'),
        ('time_msc', 'i8'),
        ('bid', 'f4'),
        ('ask', 'f4'),
        ('last', 'f4'),
        ('volume', 'i4'),
        ('flags', 'i4')
    ]

    # Tickãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åãƒªã‚¹ãƒˆ
    TICK_FIELDS = ['time', 'time_msc', 'bid', 'ask', 'last', 'volume', 'flags']

    def __init__(
        self,
        output_path: str,
        compression: Optional[str] = None,
        logger=None
    ):
        """
        åˆæœŸåŒ–
        
        Args:
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            compression: åœ§ç¸®æ–¹å¼ï¼ˆNone/"gzip"/"lzf"ï¼‰
            logger: ãƒ­ã‚¬ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        self.output_path = Path(output_path)
        self.compression = compression
        self.logger = logger
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
    
    def _log(self, level: str, msg: str) -> None:
        """ãƒ­ã‚°å‡ºåŠ›"""
        if self.logger:
            getattr(self.logger, level)(msg)
    
    def backup_existing(self, timestamp_format: str = "%Y%m%d_%H%M%S") -> None:
        """
        æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

        Args:
            timestamp_format: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        """
        if not self.output_path.exists():
            return
        
        # JSTæ—¥æ™‚ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ç”Ÿæˆ
        jst_tz = timezone(timedelta(hours=9))
        mtime = datetime.fromtimestamp(
            self.output_path.stat().st_mtime,
            tz=jst_tz
        )
        timestamp_str = mtime.strftime(timestamp_format)
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        backup_name = f"{timestamp_str}_{self.output_path.name}"
        backup_path = self.output_path.parent / backup_name
        
        # ãƒªãƒãƒ¼ãƒ 
        self.output_path.rename(backup_path)
        self._log('info', f"ğŸ“¦ æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_name}")
    
    def write_bar_data(
        self,
        timeframe: str,
        data: np.ndarray
    ) -> None:
        """
        ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿

        Args:
            timeframe: ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆä¾‹: "M5"ï¼‰
            data: ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆN, 8ï¼‰[time, open, high, low, close, tick_volume, spread, real_volume]
        """
        with h5py.File(self.output_path, 'a') as f:
            dataset_path = f"{timeframe}/data"
            
            if dataset_path in f:
                del f[dataset_path]
            
            # dtypeã‚’æŒ‡å®šã›ãšã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å‹ã‚’ä¿æŒ
            f.create_dataset(
                dataset_path,
                data=data,
                compression=self.compression
            )
            
            self._log('debug', f"ğŸ’¾ {timeframe}ãƒãƒ¼ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {data.shape}")
    
    def write_tick_data(
        self,
        data: List[Dict[str, Any]]
    ) -> None:
        """
        Tickãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿ï¼ˆä¸Šæ›¸ããƒ¢ãƒ¼ãƒ‰ï¼‰

        Args:
            data: Tickãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        if not data:
            self._log('warning', "âš ï¸  Tickãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return
        
        # æ§‹é€ åŒ–é…åˆ—ã«å¤‰æ›
        tick_array = self._convert_ticks_to_array(data)
        
        with h5py.File(self.output_path, 'a') as f:
            dataset_path = "ticks/data"
            
            if dataset_path in f:
                del f[dataset_path]
            
            f.create_dataset(
                dataset_path,
                data=tick_array,
                compression=self.compression
            )
            
            self._log('debug', f"ğŸ’¾ Tickãƒ‡ãƒ¼ã‚¿ä¿å­˜: {len(data)}ä»¶")
    
    def clear_tick_data(self) -> None:
        """
        æ—¢å­˜ã®Tickãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆæœˆåˆ†å‰²å–å¾—ã®åˆå›ã‚¯ãƒªãƒ¼ãƒ³ç”¨ï¼‰
        """
        if not self.output_path.exists():
            self._log('debug', "ğŸ—‘ï¸  clear_tick_data: ãƒ•ã‚¡ã‚¤ãƒ«æœªå­˜åœ¨")
            return
        
        with h5py.File(self.output_path, 'a') as f:
            dataset_path = "ticks/data"
            
            self._log('debug', f"ğŸ—‘ï¸  clear_tick_data: '{dataset_path}' in f = {dataset_path in f}")
            self._log('debug', f"ğŸ—‘ï¸  clear_tick_data: ç¾åœ¨ã®ã‚­ãƒ¼ = {list(f.keys())}")
            
            if dataset_path in f:
                del f[dataset_path]
                self._log('debug', f"ğŸ—‘ï¸  æ—¢å­˜Tickãƒ‡ãƒ¼ã‚¿å‰Šé™¤å®Œäº†")
                self._log('debug', f"ğŸ—‘ï¸  å‰Šé™¤å¾Œã®ã‚­ãƒ¼ = {list(f.keys())}")
            else:
                self._log('debug', "ğŸ—‘ï¸  clear_tick_data: '{dataset_path}' å­˜åœ¨ã›ãš")
    
    def append_tick_data(
        self,
        data: List[Dict[str, Any]]
    ) -> None:
        """
        Tickãƒ‡ãƒ¼ã‚¿ã‚’è¿½è¨˜ï¼ˆæœˆåˆ†å‰²ç”¨ï¼‰

        Args:
            data: Tickãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        if not data:
            self._log('warning', "âš ï¸  Tickãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™")
            return
        
        # æ§‹é€ åŒ–é…åˆ—ã«å¤‰æ›
        new_array = self._convert_ticks_to_array(data)
        
        with h5py.File(self.output_path, 'a') as f:
            dataset_path = "ticks/data"
            
            self._log('debug', f"ğŸ’¾ append_tick_data: '{dataset_path}' in f = {dataset_path in f}")
            self._log('debug', f"ğŸ’¾ append_tick_data: ç¾åœ¨ã®ã‚­ãƒ¼ = {list(f.keys())}")
            
            if dataset_path not in f:
                # åˆå›: æ–°è¦ä½œæˆ
                self._log('debug', f"ğŸ’¾ Tickåˆå›ä½œæˆ: {len(new_array)}ä»¶")
                f.create_dataset(
                    dataset_path,
                    data=new_array,
                    maxshape=(None,),
                    compression=self.compression
                )
            else:
                # è¿½è¨˜: ãƒªã‚µã‚¤ã‚ºã—ã¦è¿½åŠ 
                dataset = f[dataset_path]
                old_size = dataset.shape[0]
                new_size = old_size + len(new_array)
                
                self._log('debug', f"ğŸ’¾ Tickè¿½è¨˜: {old_size:,} â†’ {new_size:,}ä»¶ (+{len(new_array):,})")
                
                dataset.resize((new_size,))
                dataset[old_size:new_size] = new_array
    
    def _convert_ticks_to_array(
        self,
        data: List[Dict[str, Any]]
    ) -> np.ndarray:
        """
        Tickãƒ‡ãƒ¼ã‚¿ã‚’NumPyæ§‹é€ åŒ–é…åˆ—ã«å¤‰æ›

        Args:
            data: Tickãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ

        Returns:
            æ§‹é€ åŒ–é…åˆ—
        """
        tick_array = np.array([
            (
                tick['time'],
                tick['time_msc'],
                tick['bid'],
                tick['ask'],
                tick.get('last', 0.0),
                tick.get('volume', 0),
                tick.get('flags', 0)
            )
            for tick in data
        ], dtype=self.TICK_DTYPE)

        return tick_array
    
    def write_metadata(
        self,
        metadata: Dict[str, Any]
    ) -> None:
        """
        ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿

        Args:
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸
        """
        with h5py.File(self.output_path, 'a') as f:
            # JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜
            metadata_json = json.dumps(metadata, ensure_ascii=False, indent=2)
            
            if 'metadata' in f:
                del f['metadata']
            
            f.create_dataset(
                'metadata',
                data=metadata_json.encode('utf-8')
            )
            
            self._log('debug', "ğŸ’¾ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†")
    
    def get_file_size_mb(self) -> float:
        """
        ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå–å¾—
        
        Returns:
            ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºï¼ˆMBï¼‰
        """
        if not self.output_path.exists():
            return 0.0
        
        size_bytes = self.output_path.stat().st_size
        return size_bytes / (1024 * 1024)
