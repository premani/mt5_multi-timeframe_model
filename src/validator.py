#!/usr/bin/env python3
"""
æ¤œè¨¼å‡¦ç†ï¼ˆç¬¬5æ®µéšï¼‰

ç›®çš„:
    å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½è©•ä¾¡

å…¥åŠ›:
    - preprocessed.h5: å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆï¼‰
    - training.pt: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«

å‡ºåŠ›:
    - validation_report.json: è©•ä¾¡æŒ‡æ¨™ãƒ¬ãƒãƒ¼ãƒˆ
    - confusion_matrix.png: æ··åŒè¡Œåˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

å®Ÿè¡Œ:
    bash ./docker_run.sh python3 src/validator.py
"""

import sys
from pathlib import Path
import yaml
import h5py
import torch
import torch.nn as nn
import numpy as np
import json
from datetime import datetime
from typing import Dict, Tuple, Any
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    mean_absolute_error, mean_squared_error, r2_score,
    confusion_matrix, classification_report
)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.utils.logging_manager import LoggingManager


class SimpleLSTMModel(nn.Module):
    """ã‚·ãƒ³ãƒ—ãƒ«LSTMãƒ¢ãƒ‡ãƒ«ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜æ§‹é€ ï¼‰"""
    
    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 2):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.2
        )
        
        # Direction head (3ã‚¯ãƒ©ã‚¹: UP/DOWN/NEUTRAL)
        self.direction_head = nn.Sequential(
            nn.Linear(hidden_size, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 3)
        )
        
        # Magnitude head (ä¾¡æ ¼å¹…å›å¸°)
        self.magnitude_head = nn.Sequential(
            nn.Linear(hidden_size, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 1)
        )
    
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Args:
            x: (batch, seq_len, features)
        
        Returns:
            direction_logits: (batch, 3)
            magnitude_pred: (batch, 1)
        """
        # LSTM
        lstm_out, _ = self.lstm(x)
        last_hidden = lstm_out[:, -1, :]
        
        # ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯å‡ºåŠ›
        direction_logits = self.direction_head(last_hidden)
        magnitude_pred = self.magnitude_head(last_hidden)
        
        return direction_logits, magnitude_pred


class Validator:
    """æ¤œè¨¼å‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = LoggingManager.get_logger(__name__)
        self.device = torch.device(config['batch']['device'] if torch.cuda.is_available() else 'cpu')
        
        self.logger.info(f"ğŸ¯ æ¤œè¨¼å‡¦ç†é–‹å§‹")
        self.logger.info(f"   ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
    
    def load_data(self) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        input_path = Path(self.config['input']['preprocessed_file'])
        
        self.logger.info(f"ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {input_path.name}")
        
        with h5py.File(input_path, 'r') as f:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
            test_sequences = f['test/sequences'][:]
            test_direction = f['test/labels/direction'][:]
            test_magnitude = f['test/labels/magnitude'][:]
            
            self.logger.info(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test_sequences.shape}")
            self.logger.info(f"   Direction: {test_direction.shape}")
            self.logger.info(f"   Magnitude: {test_magnitude.shape}")
        
        # Tensorã«å¤‰æ›
        test_sequences = torch.from_numpy(test_sequences).float()
        test_direction = torch.from_numpy(test_direction).long()
        test_magnitude = torch.from_numpy(test_magnitude).float()
        
        return test_sequences, test_direction, test_magnitude
    
    def load_model(self, input_size: int) -> SimpleLSTMModel:
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        model_path = Path(self.config['input']['model_file'])
        
        self.logger.info(f"ğŸ”§ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {model_path.name}")
        
        # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
        model = SimpleLSTMModel(
            input_size=input_size,
            hidden_size=128,
            num_layers=2
        )
        
        # é‡ã¿èª­ã¿è¾¼ã¿
        checkpoint = torch.load(model_path, map_location=self.device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(self.device)
        model.eval()
        
        self.logger.info(f"   ã‚¨ãƒãƒƒã‚¯: {checkpoint['epoch']}")
        self.logger.info(f"   å­¦ç¿’ç²¾åº¦: {checkpoint.get('train_accuracy', 'N/A')}")
        
        return model
    
    def predict(
        self,
        model: SimpleLSTMModel,
        sequences: torch.Tensor,
        batch_size: int
    ) -> Tuple[np.ndarray, np.ndarray]:
        """æ¨è«–å®Ÿè¡Œ"""
        self.logger.info(f"ğŸ”„ æ¨è«–å®Ÿè¡Œä¸­...")
        
        all_direction_preds = []
        all_magnitude_preds = []
        
        with torch.no_grad():
            for i in range(0, len(sequences), batch_size):
                batch = sequences[i:i+batch_size].to(self.device)
                
                # æ¨è«–
                direction_logits, magnitude_pred = model(batch)
                
                # Direction: argmax
                direction_pred = torch.argmax(direction_logits, dim=1).cpu().numpy()
                all_direction_preds.append(direction_pred)
                
                # Magnitude
                magnitude_pred = magnitude_pred.squeeze().cpu().numpy()
                all_magnitude_preds.append(magnitude_pred)
        
        # çµåˆ
        direction_preds = np.concatenate(all_direction_preds)
        magnitude_preds = np.concatenate(all_magnitude_preds)
        
        self.logger.info(f"   æ¨è«–å®Œäº†: {len(direction_preds)} ã‚µãƒ³ãƒ—ãƒ«")
        
        return direction_preds, magnitude_preds
    
    def evaluate_direction(
        self,
        y_true: np.ndarray,
        y_pred: np.ndarray
    ) -> Dict[str, Any]:
        """æ–¹å‘äºˆæ¸¬è©•ä¾¡"""
        self.logger.info(f"ğŸ“Š æ–¹å‘äºˆæ¸¬è©•ä¾¡")
        
        # å…¨ä½“ç²¾åº¦
        accuracy = accuracy_score(y_true, y_pred)
        self.logger.info(f"   Accuracy: {accuracy:.4f}")
        
        # ã‚¯ãƒ©ã‚¹åˆ¥æŒ‡æ¨™
        precision = precision_score(y_true, y_pred, average=None, zero_division=0)
        recall = recall_score(y_true, y_pred, average=None, zero_division=0)
        f1 = f1_score(y_true, y_pred, average=None, zero_division=0)
        
        class_names = ['DOWN', 'NEUTRAL', 'UP']
        for i, name in enumerate(class_names):
            self.logger.info(f"   {name:8s}: Precision={precision[i]:.4f}, Recall={recall[i]:.4f}, F1={f1[i]:.4f}")
        
        # æ··åŒè¡Œåˆ—
        cm = confusion_matrix(y_true, y_pred)
        self.logger.info(f"   æ··åŒè¡Œåˆ—:\n{cm}")
        
        # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
        report = classification_report(y_true, y_pred, target_names=class_names, zero_division=0)
        
        return {
            'accuracy': float(accuracy),
            'precision': precision.tolist(),
            'recall': recall.tolist(),
            'f1_score': f1.tolist(),
            'confusion_matrix': cm.tolist(),
            'classification_report': report
        }
    
    def evaluate_magnitude(
        self,
        y_true: np.ndarray,
        y_pred: np.ndarray
    ) -> Dict[str, float]:
        """ä¾¡æ ¼å¹…äºˆæ¸¬è©•ä¾¡"""
        self.logger.info(f"ğŸ“Š ä¾¡æ ¼å¹…äºˆæ¸¬è©•ä¾¡")
        
        # MAE
        mae = mean_absolute_error(y_true, y_pred)
        self.logger.info(f"   MAE: {mae:.4f} pips")
        
        # RMSE
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        self.logger.info(f"   RMSE: {rmse:.4f} pips")
        
        # RÂ²
        r2 = r2_score(y_true, y_pred)
        self.logger.info(f"   RÂ²: {r2:.4f}")
        
        return {
            'mae': float(mae),
            'rmse': float(rmse),
            'r2': float(r2)
        }
    
    def save_report(self, report: Dict[str, Any], output_dir: Path):
        """ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = output_dir / f"fx_lstm_model_{timestamp}_validation_report.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"ğŸ’¾ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path.name}")
    
    def run(self):
        """æ¤œè¨¼å®Ÿè¡Œ"""
        try:
            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            test_sequences, test_direction, test_magnitude = self.load_data()
            
            # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
            input_size = test_sequences.shape[2]
            model = self.load_model(input_size)
            
            # æ¨è«–
            batch_size = self.config['batch']['size']
            direction_preds, magnitude_preds = self.predict(model, test_sequences, batch_size)
            
            # è©•ä¾¡
            direction_metrics = self.evaluate_direction(
                test_direction.numpy(),
                direction_preds
            )
            
            magnitude_metrics = self.evaluate_magnitude(
                test_magnitude.numpy(),
                magnitude_preds
            )
            
            # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            report = {
                'timestamp': datetime.now().isoformat(),
                'model_file': self.config['input']['model_file'],
                'preprocessed_file': self.config['input']['preprocessed_file'],
                'test_samples': len(test_sequences),
                'direction_metrics': direction_metrics,
                'magnitude_metrics': magnitude_metrics
            }
            
            # ä¿å­˜
            output_dir = Path(self.config['output']['report_dir'])
            output_dir.mkdir(parents=True, exist_ok=True)
            self.save_report(report, output_dir)
            
            self.logger.info(f"âœ… æ¤œè¨¼å®Œäº†")
            
        except Exception as e:
            self.logger.error(f"âŒ æ¤œè¨¼å¤±æ•—: {e}", exc_info=True)
            raise


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # è¨­å®šèª­ã¿è¾¼ã¿
    config_path = Path("config/validator.yaml")
    if not config_path.exists():
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")
        print(f"   ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„:")
        print(f"   cp config/validator.template.yaml config/validator.yaml")
        sys.exit(1)
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # æ¤œè¨¼å®Ÿè¡Œ
    validator = Validator(config)
    validator.run()


if __name__ == "__main__":
    main()
