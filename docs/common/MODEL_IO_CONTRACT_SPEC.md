# MODEL_IO_CONTRACT_SPEC.md - ãƒ¢ãƒ‡ãƒ«å…¥å‡ºåŠ›å¥‘ç´„ä»•æ§˜

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0  
**æ›´æ–°æ—¥**: 2025-10-22

---

## ğŸ“‹ ç›®çš„

ãƒ¢ãƒ‡ãƒ«å…¥å‡ºåŠ›ã®å½¢çŠ¶ãƒ»åˆ—é †ãƒ»å‹ãƒ»ã‚»ãƒãƒ³ãƒ†ã‚£ã‚¯ã‚¹ã‚’æ˜ç¢ºã«å®šç¾©ã—ã€å­¦ç¿’ãƒ»æ¨è«–ãƒ»ONNXå¤‰æ›é–“ã®æ•´åˆæ€§ã‚’ä¿è¨¼ã™ã‚‹ã€‚

---

## é …ç›®11å¯¾å¿œ: å…¥åŠ›å¥‘ç´„é½Ÿé½¬é˜²æ­¢

**ç›®çš„**: åˆ—é †/shapeä¸ä¸€è‡´ã¯ONNXæ¨è«–å¤±æ•—ã‚„attention weightç„¡æ„å‘³åŒ–ï¼ˆåˆ—ã‚·ãƒ£ãƒƒãƒ•ãƒ«ï¼‰ã‚’èª˜ç™º

**è§£æ±ºç­–**: å…¥åŠ›å¥‘ç´„ã‚’æ˜ç¤ºçš„ã«å®šç¾©ã—ã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒãƒƒã‚·ãƒ¥ã§ç…§åˆ

---

## ğŸ”¢ å…¥åŠ›å¥‘ç´„å®šç¾©

### ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ åˆ¥å…¥åŠ›å½¢çŠ¶

```python
INPUT_CONTRACT = {
    "version": "v1.0",
    "schema_hash": "a3f2b1c8e7d9f3a1",  # å¥‘ç´„å¤‰æ›´æ™‚ã«æ›´æ–°
    
    "timeframes": {
        "M1": {
            "sequence_length": 480,
            "feature_count": None,  # å®Ÿè¡Œæ™‚æ±ºå®š
            "dtype": "float32",
            "shape": "(batch, 480, F)",
            "semantics": "ç›´è¿‘480åˆ†ï¼ˆ8æ™‚é–“ï¼‰ã®M1ç‰¹å¾´é‡"
        },
        "M5": {
            "sequence_length": 288,
            "feature_count": None,
            "dtype": "float32",
            "shape": "(batch, 288, F)",
            "semantics": "ç›´è¿‘24æ™‚é–“ã®M5ç‰¹å¾´é‡"
        },
        "M15": {
            "sequence_length": 192,
            "feature_count": None,
            "dtype": "float32",
            "shape": "(batch, 192, F)",
            "semantics": "ç›´è¿‘48æ™‚é–“ã®M15ç‰¹å¾´é‡"
        },
        "H1": {
            "sequence_length": 96,
            "feature_count": None,
            "dtype": "float32",
            "shape": "(batch, 96, F)",
            "semantics": "ç›´è¿‘4æ—¥ã®H1ç‰¹å¾´é‡"
        },
        "H4": {
            "sequence_length": 48,
            "feature_count": None,
            "dtype": "float32",
            "shape": "(batch, 48, F)",
            "semantics": "ç›´è¿‘8æ—¥ã®H4ç‰¹å¾´é‡"
        }
    },
    
    "masks": {
        "M1": {
            "shape": "(batch, 480)",
            "dtype": "float32",
            "semantics": "1.0=æœ‰åŠ¹, 0.0=æ¬ æ/filled, 0.6=filledæ¸›è¡°"
        },
        "M5": {
            "shape": "(batch, 288)",
            "dtype": "float32",
            "semantics": "1.0=æœ‰åŠ¹, 0.0=æ¬ æ/filled, 0.6=filledæ¸›è¡°"
        },
        "M15": {
            "shape": "(batch, 192)",
            "dtype": "float32",
            "semantics": "1.0=æœ‰åŠ¹, 0.0=æ¬ æ/filled, 0.6=filledæ¸›è¡°"
        },
        "H1": {
            "shape": "(batch, 96)",
            "dtype": "float32",
            "semantics": "1.0=æœ‰åŠ¹, 0.0=æ¬ æ/filled, 0.6=filledæ¸›è¡°"
        },
        "H4": {
            "shape": "(batch, 48)",
            "dtype": "float32",
            "semantics": "1.0=æœ‰åŠ¹, 0.0=æ¬ æ/filled, 0.6=filledæ¸›è¡°"
        }
    },
    
    "feature_order": {
        "requirement": "å…¨TFã§çµ±ä¸€ã•ã‚ŒãŸåˆ—é †ã‚’ä¿æŒ",
        "validation": "feature_names_hashæ¤œè¨¼å¿…é ˆ",
        "persistence": "HDF5 /metadata/feature_names ã«ä¿å­˜"
    }
}
```

---

## ğŸ“¤ å‡ºåŠ›å¥‘ç´„å®šç¾©

### å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰å‡ºåŠ›

```python
OUTPUT_CONTRACT_TRAINING = {
    "version": "v1.0",
    
    "direction": {
        "shape": "(batch, 3)",
        "dtype": "float32",
        "semantics": "æ–¹å‘ç¢ºç‡ [UP, DOWN, NEUTRAL]",
        "constraints": "sum=1.0, range=[0,1]"
    },
    
    "magnitude_scalp": {
        "shape": "(batch, 1)",
        "dtype": "float32",
        "semantics": "ã‚¹ã‚«ãƒ«ãƒ—ä¾¡æ ¼å¹…ï¼ˆpipsï¼‰",
        "range": "[0.0, 2.0]"
    },
    
    "magnitude_swing": {
        "shape": "(batch, 1)",
        "dtype": "float32",
        "semantics": "ã‚¹ã‚¤ãƒ³ã‚°ä¾¡æ ¼å¹…ï¼ˆpipsï¼‰",
        "range": "[0.0, 5.0]"
    },
    
    "trend_strength": {
        "shape": "(batch, 1)",
        "dtype": "float32",
        "semantics": "ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã‚¹ã‚³ã‚¢",
        "range": "[0.0, 1.0]",
        "interpretation": "<0.3=scalp, >0.7=swing, 0.3-0.7=æ··åˆ"
    }
}
```

### æ¨è«–ãƒ¢ãƒ¼ãƒ‰å‡ºåŠ›

```python
OUTPUT_CONTRACT_INFERENCE = {
    "version": "v1.0",
    
    "predictions": {
        "direction_probs": {
            "shape": "(3,)",
            "dtype": "float32",
            "order": "[UP, DOWN, NEUTRAL]"
        },
        "magnitude_scalp": {
            "value": "float32",
            "unit": "pips"
        },
        "magnitude_swing": {
            "value": "float32",
            "unit": "pips"
        },
        "trend_strength": {
            "value": "float32",
            "range": "[0.0, 1.0]"
        },
        "confidence": {
            "value": "float32",
            "range": "[0.0, 1.0]",
            "computation": "max(direction_probs)"
        }
    },
    
    "metadata": {
        "inference_timestamp": "datetime",
        "model_version": "str",
        "input_quality_score": "float32"
    }
}
```

---

## ğŸ”’ å¥‘ç´„æ¤œè¨¼æ©Ÿæ§‹

### å…¥åŠ›å¥‘ç´„æ¤œè¨¼

```python
import hashlib
import json
from typing import Dict, Any

class InputContractValidator:
    """å…¥åŠ›å¥‘ç´„æ¤œè¨¼å™¨"""
    
    def __init__(self, contract: dict):
        self.contract = contract
        self.expected_hash = contract["schema_hash"]
    
    def compute_contract_hash(self, feature_names: list, shapes: dict) -> str:
        """
        å¥‘ç´„ãƒãƒƒã‚·ãƒ¥è¨ˆç®—
        
        Args:
            feature_names: ç‰¹å¾´é‡åˆ—åãƒªã‚¹ãƒˆï¼ˆé †åºé‡è¦ï¼‰
            shapes: TFåˆ¥å½¢çŠ¶è¾æ›¸
        
        Returns:
            contract_hash: MD5ãƒãƒƒã‚·ãƒ¥ï¼ˆå…ˆé ­16æ–‡å­—ï¼‰
        """
        contract_str = json.dumps({
            "feature_names": feature_names,
            "shapes": shapes,
            "version": self.contract["version"]
        }, sort_keys=True)
        
        return hashlib.md5(contract_str.encode()).hexdigest()[:16]
    
    def validate_input(
        self,
        inputs: Dict[str, Any],
        feature_names: list
    ) -> Dict[str, Any]:
        """
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®å¥‘ç´„é©åˆæ€§æ¤œè¨¼
        
        Args:
            inputs: {
                "M1": (batch, 480, F),
                "M5": (batch, 288, F),
                "masks": {"M1": (batch, 480), ...}
            }
            feature_names: ç‰¹å¾´é‡åãƒªã‚¹ãƒˆ
        
        Returns:
            validation_result: {
                "valid": bool,
                "errors": list[str],
                "warnings": list[str]
            }
        """
        errors = []
        warnings = []
        
        # 1. TFå½¢çŠ¶æ¤œè¨¼
        for tf, expected in self.contract["timeframes"].items():
            if tf not in inputs:
                errors.append(f"Missing timeframe: {tf}")
                continue
            
            actual_shape = inputs[tf].shape
            expected_seq_len = expected["sequence_length"]
            
            if actual_shape[1] != expected_seq_len:
                errors.append(
                    f"{tf} sequence length mismatch: "
                    f"expected={expected_seq_len}, actual={actual_shape[1]}"
                )
            
            # dtypeæ¤œè¨¼
            if str(inputs[tf].dtype) != expected["dtype"]:
                warnings.append(
                    f"{tf} dtype mismatch: "
                    f"expected={expected['dtype']}, actual={inputs[tf].dtype}"
                )
        
        # 2. ãƒã‚¹ã‚¯å½¢çŠ¶æ¤œè¨¼
        if "masks" in inputs:
            for tf, expected in self.contract["masks"].items():
                if tf not in inputs["masks"]:
                    errors.append(f"Missing mask: {tf}")
                    continue
                
                actual_mask_shape = inputs["masks"][tf].shape
                expected_shape_str = expected["shape"]
                # ä¾‹: "(batch, 480)" ã‹ã‚‰ 480 ã‚’æŠ½å‡º
                expected_seq = int(expected_shape_str.split(",")[1].strip().rstrip(")"))
                
                if actual_mask_shape[1] != expected_seq:
                    errors.append(
                        f"{tf} mask shape mismatch: "
                        f"expected seq={expected_seq}, actual={actual_mask_shape[1]}"
                    )
        
        # 3. ç‰¹å¾´é‡åˆ—é †ãƒãƒƒã‚·ãƒ¥æ¤œè¨¼
        shapes_dict = {
            tf: list(inputs[tf].shape)
            for tf in self.contract["timeframes"].keys()
            if tf in inputs
        }
        
        actual_hash = self.compute_contract_hash(feature_names, shapes_dict)
        
        if actual_hash != self.expected_hash:
            warnings.append(
                f"Contract hash mismatch: "
                f"expected={self.expected_hash}, actual={actual_hash}. "
                f"Feature names or shapes may have changed."
            )
        
        return {
            "valid": len(errors) == 0,
            "errors": errors,
            "warnings": warnings
        }


# ä½¿ç”¨ä¾‹: å­¦ç¿’é–‹å§‹æ™‚ã®æ¤œè¨¼
validator = InputContractValidator(INPUT_CONTRACT)

# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‹ã‚‰å–å¾—ã—ãŸå…¥åŠ›
batch_inputs = {
    "M1": torch.randn(32, 480, 120),
    "M5": torch.randn(32, 288, 120),
    "M15": torch.randn(32, 192, 120),
    "H1": torch.randn(32, 96, 120),
    "H4": torch.randn(32, 48, 120),
    "masks": {
        "M1": torch.ones(32, 480),
        "M5": torch.ones(32, 288),
        "M15": torch.ones(32, 192),
        "H1": torch.ones(32, 96),
        "H4": torch.ones(32, 48),
    }
}

# ç‰¹å¾´é‡åï¼ˆHDF5ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
feature_names = load_feature_names_from_hdf5("preprocessed.h5")

# æ¤œè¨¼å®Ÿè¡Œ
result = validator.validate_input(batch_inputs, feature_names)

if not result["valid"]:
    logger.error(f"å…¥åŠ›å¥‘ç´„é•å: {result['errors']}")
    raise ValueError("Input contract validation failed")

if result["warnings"]:
    logger.warning(f"å…¥åŠ›å¥‘ç´„è­¦å‘Š: {result['warnings']}")
```

---

## ğŸ“‹ å¥‘ç´„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜

### HDF5ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å½¢å¼

```python
def save_contract_metadata(h5_file, contract: dict, feature_names: list):
    """
    HDF5ãƒ•ã‚¡ã‚¤ãƒ«ã«å¥‘ç´„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    
    Args:
        h5_file: h5py.File object
        contract: INPUT_CONTRACTè¾æ›¸
        feature_names: ç‰¹å¾´é‡åãƒªã‚¹ãƒˆ
    """
    meta_group = h5_file.require_group("metadata/io_contract")
    
    # å¥‘ç´„ãƒãƒ¼ã‚¸ãƒ§ãƒ³
    meta_group.attrs["version"] = contract["version"]
    meta_group.attrs["schema_hash"] = contract["schema_hash"]
    
    # TFåˆ¥å½¢çŠ¶
    for tf, spec in contract["timeframes"].items():
        tf_group = meta_group.require_group(f"timeframes/{tf}")
        tf_group.attrs["sequence_length"] = spec["sequence_length"]
        tf_group.attrs["dtype"] = spec["dtype"]
        tf_group.attrs["semantics"] = spec["semantics"]
    
    # ç‰¹å¾´é‡åï¼ˆåˆ—é †ä¿æŒï¼‰
    meta_group.create_dataset(
        "feature_names",
        data=[name.encode() for name in feature_names]
    )
    
    # å¥‘ç´„ãƒãƒƒã‚·ãƒ¥æ¤œè¨¼ç”¨
    validator = InputContractValidator(contract)
    shapes = {
        tf: [None, spec["sequence_length"], len(feature_names)]
        for tf, spec in contract["timeframes"].items()
    }
    contract_hash = validator.compute_contract_hash(feature_names, shapes)
    meta_group.attrs["computed_hash"] = contract_hash
    
    logger.info(f"å¥‘ç´„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: version={contract['version']}, hash={contract_hash}")


# ä½¿ç”¨ä¾‹: å‰å‡¦ç†å®Œäº†æ™‚
with h5py.File("preprocessed.h5", "a") as h5f:
    save_contract_metadata(h5f, INPUT_CONTRACT, feature_names)
```

---

## ğŸ”„ ONNXå¤‰æ›æ™‚ã®å¥‘ç´„æ¤œè¨¼

```python
def verify_onnx_contract(onnx_model_path: str, contract: dict):
    """
    ONNXå¤‰æ›å¾Œã®å…¥å‡ºåŠ›å¥‘ç´„æ¤œè¨¼
    
    Args:
        onnx_model_path: ONNXãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹
        contract: INPUT_CONTRACTè¾æ›¸
    """
    import onnx
    
    model = onnx.load(onnx_model_path)
    
    # å…¥åŠ›å½¢çŠ¶æ¤œè¨¼
    for input_tensor in model.graph.input:
        tensor_name = input_tensor.name
        tensor_shape = [
            dim.dim_value if dim.dim_value > 0 else -1
            for dim in input_tensor.type.tensor_type.shape.dim
        ]
        
        # TFåæŠ½å‡ºï¼ˆä¾‹: "input_M1" â†’ "M1"ï¼‰
        tf_name = tensor_name.split("_")[-1]
        
        if tf_name in contract["timeframes"]:
            expected_seq = contract["timeframes"][tf_name]["sequence_length"]
            actual_seq = tensor_shape[1] if len(tensor_shape) > 1 else None
            
            if actual_seq != expected_seq:
                raise ValueError(
                    f"ONNX input shape mismatch for {tf_name}: "
                    f"expected seq={expected_seq}, actual={actual_seq}"
                )
    
    # å‡ºåŠ›å½¢çŠ¶æ¤œè¨¼
    for output_tensor in model.graph.output:
        tensor_name = output_tensor.name
        tensor_shape = [
            dim.dim_value if dim.dim_value > 0 else -1
            for dim in output_tensor.type.tensor_type.shape.dim
        ]
        
        logger.info(f"ONNXå‡ºåŠ›æ¤œè¨¼: {tensor_name}, shape={tensor_shape}")
    
    logger.info("âœ… ONNXå¥‘ç´„æ¤œè¨¼: æˆåŠŸ")


# ä½¿ç”¨ä¾‹: ONNXå¤‰æ›å¾Œ
verify_onnx_contract("model.onnx", INPUT_CONTRACT)
```

---

## ğŸ“Š å¥‘ç´„å¤‰æ›´ç®¡ç†

### ãƒãƒ¼ã‚¸ãƒ§ãƒ³å±¥æ­´

| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | æ—¥ä»˜ | å¤‰æ›´å†…å®¹ | schema_hash |
|-----------|------|---------|-------------|
| v1.0 | 2025-10-22 | åˆç‰ˆä½œæˆ | a3f2b1c8e7d9f3a1 |

### å¥‘ç´„å¤‰æ›´æ™‚ã®æ‰‹é †

1. **INPUT_CONTRACTæ›´æ–°**: `version`ã¨`schema_hash`ã‚’å¤‰æ›´
2. **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜**: å‰å‡¦ç†æ™‚ã«æ–°å¥‘ç´„ã‚’ä¿å­˜
3. **æ¤œè¨¼ã‚³ãƒ¼ãƒ‰æ›´æ–°**: `InputContractValidator`ã§æ–°å¥‘ç´„æ¤œè¨¼
4. **ONNXå†å¤‰æ›**: æ–°å¥‘ç´„ã«åŸºã¥ããƒ¢ãƒ‡ãƒ«å†å¤‰æ›
5. **ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ**: å­¦ç¿’ãƒ»æ¨è«–ãƒ»ONNXæ¨è«–ã®å…¨ãƒ‘ã‚¹æ¤œè¨¼

---

## ğŸ¯ KPIãƒ»æˆåŠŸæ¡ä»¶ï¼ˆé …ç›®11ï¼‰

- **æ¨è«–åˆ—æ•´åˆã‚¨ãƒ©ãƒ¼**: 0ä»¶
- **ONNXå¤‰æ›æˆåŠŸç‡**: 100%
- **å¥‘ç´„ãƒãƒƒã‚·ãƒ¥ä¸ä¸€è‡´æ¤œå‡º**: å³åº§ã«WARNINGç™ºç«
- **ç‰¹å¾´é‡åˆ—é †ã‚·ãƒ£ãƒƒãƒ•ãƒ«æ¤œå‡º**: 100%

---

## ğŸ”— é–¢é€£ä»•æ§˜

- [PREPROCESSOR_SPEC.md](./PREPROCESSOR_SPEC.md) - å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
- [TRAINER_SPEC.md](./TRAINER_SPEC.md) - ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
- [ONNX_CONVERTER_SPEC.md](./ONNX_CONVERTER_SPEC.md) - ONNXå¤‰æ›
- [MULTI_TF_FUSION_SPEC.md](./trainer/MULTI_TF_FUSION_SPEC.md) - ãƒãƒ«ãƒTFèåˆ

---

## ğŸ”® å°†æ¥æ‹¡å¼µ

- å‹•çš„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã‚µãƒãƒ¼ãƒˆï¼ˆå¯å¤‰é•·å…¥åŠ›ï¼‰
- ãƒãƒ«ãƒã‚·ãƒ³ãƒœãƒ«å¯¾å¿œï¼ˆé€šè²¨ãƒšã‚¢åˆ¥å¥‘ç´„ï¼‰
- ã‚«ã‚¹ã‚¿ãƒ headè¿½åŠ æ™‚ã®å¥‘ç´„è‡ªå‹•æ›´æ–°
