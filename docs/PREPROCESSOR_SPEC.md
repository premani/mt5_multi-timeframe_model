# PREPROCESSOR_SPEC.md

**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 2.0
**æ›´æ–°æ—¥**: 2025-10-22
**è²¬ä»»è€…**: core-team
**å‡¦ç†æ®µéš**: ç¬¬3æ®µéš: å‰å‡¦ç†ï¼ˆæ­£è¦åŒ–ãƒ»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–ï¼‰

---

## ğŸ“‹ ç›®çš„

`src/preprocessor.py` ãŒ**ç¬¬2æ®µéšã§è¨ˆç®—æ¸ˆã¿ã®ç‰¹å¾´é‡**ã‚’å­¦ç¿’å¯èƒ½ãªå½¢å¼ã«å¤‰æ›ã™ã‚‹ã€‚

**è²¬ä»»ç¯„å›²**:
- ç‰¹å¾´é‡ã®æ­£è¦åŒ–ï¼ˆRobustScalerç­‰ï¼‰
- ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–ï¼ˆæ™‚ç³»åˆ—ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç”Ÿæˆï¼‰
- å“è³ªæ¤œè¨¼ï¼ˆNaN/å®šæ•°åˆ—/é«˜ç›¸é–¢é™¤å¤–ï¼‰
- æœªæ¥ãƒªãƒ¼ã‚¯æ¤œæŸ»

**å‡¦ç†æ®µéšã®åˆ†é›¢**:
- **ç¬¬1æ®µéšï¼ˆãƒ‡ãƒ¼ã‚¿åé›†ï¼‰**: `src/data_collector.py` â†’ `data/data_collector.h5`
- **ç¬¬2æ®µéšï¼ˆç‰¹å¾´é‡è¨ˆç®—ï¼‰**: `src/feature_calculator.py` â†’ `data/feature_calculator.h5`
- **ç¬¬3æ®µéšï¼ˆå‰å‡¦ç†ï¼‰**: `src/preprocessor.py` â†’ `data/preprocessor.h5`

---

## ğŸ”„ å‡¦ç†ãƒ•ãƒ­ãƒ¼

```
å…¥åŠ›: models/*_features.h5ï¼ˆç¬¬2æ®µéšã§ç”Ÿæˆï¼‰
  â”œâ”€ features: (N, 50-80) è¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡
  â”œâ”€ feature_names: ç‰¹å¾´é‡åãƒªã‚¹ãƒˆ
  â””â”€ metadata: è¨ˆç®—çµ±è¨ˆæƒ…å ±
    â†“
[ã‚¹ãƒ†ãƒƒãƒ—1: HDF5ãƒ­ãƒ¼ãƒ‰]
  - ç¬¬2æ®µéšã§è¨ˆç®—æ¸ˆã¿ã®ç‰¹å¾´é‡ã‚’èª­ã¿è¾¼ã¿
    â†“
[ã‚¹ãƒ†ãƒƒãƒ—2: å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°]
  - NaN/Inf æ¤œå‡ºãƒ»é™¤å¤–
  - å®šæ•°åˆ—é™¤å¤–ï¼ˆIQR < 1e-6ï¼‰
  - é«˜ç›¸é–¢ãƒšã‚¢é™¤å¤–ï¼ˆ|Ï| > 0.95ï¼‰
    â†“
[ã‚¹ãƒ†ãƒƒãƒ—3: æ­£è¦åŒ–]
  - RobustScaleré©ç”¨ï¼ˆå¤–ã‚Œå€¤è€æ€§ï¼‰
  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜ï¼ˆé€†å¤‰æ›ç”¨ï¼‰
    â†“
[ã‚¹ãƒ†ãƒƒãƒ—4: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–]
  - ãƒãƒ«ãƒTFåˆ¥ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ä½œæˆ
    - M1: (N, 480, F)  # 8æ™‚é–“
    - M5: (N, 288, F)  # 24æ™‚é–“
    - M15: (N, 192, F) # 48æ™‚é–“
    - H1: (N, 96, F)   # 4æ—¥
    - H4: (N, 48, F)   # 8æ—¥
    â†“
[ã‚¹ãƒ†ãƒƒãƒ—5: æœªæ¥ãƒªãƒ¼ã‚¯æ¤œæŸ»]
  - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—é †åºç¢ºèª
  - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ™‚åˆ»ã‚ˆã‚Šæœªæ¥ã®ãƒ‡ãƒ¼ã‚¿æ··å…¥ãƒã‚§ãƒƒã‚¯
    â†“
[ã‚¹ãƒ†ãƒƒãƒ—6: å“è³ªçµ±è¨ˆå‡ºåŠ›]
  - ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœ
  - æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  - ã‚·ãƒ¼ã‚±ãƒ³ã‚¹çµ±è¨ˆ
    â†“
å‡ºåŠ›: data/preprocessor.h5
  â”œâ”€ sequences: Dict[str, array] # TFåˆ¥ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
  â”œâ”€ scaler_params: bytes (JSON) # æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
  â”œâ”€ feature_names: array         # æœ€çµ‚ç‰¹å¾´é‡å
  â””â”€ metadata: bytes (JSON)       # å‡¦ç†çµ±è¨ˆ

â€» æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã€JSTæ—¥æ™‚ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ä»˜ãã§ãƒªãƒãƒ¼ãƒ é€€é¿
  ä¾‹: data/20251023_143045_preprocessor.h5
```

### ç¬¬2æ®µéšã¨ã®åˆ†é›¢

| å‡¦ç† | ç¬¬2æ®µéš (feature_calculator.py) | ç¬¬3æ®µéš (preprocessor.py) |
|------|----------------------------------|---------------------------|
| **ç‰¹å¾´é‡è¨ˆç®—** | âœ… RSI, MACD, ATR, ä¾¡æ ¼å¤‰åŒ–ç­‰ | âŒ è¨ˆç®—æ¸ˆã¿ã‚’èª­ã¿è¾¼ã‚€ã®ã¿ |
| **TFé–“ç‰¹å¾´** | âœ… M5-M1å·®åˆ†, ç›¸é–¢ç­‰ | âŒ è¨ˆç®—æ¸ˆã¿ã‚’èª­ã¿è¾¼ã‚€ã®ã¿ |
| **æ­£è¦åŒ–** | âŒ ç”Ÿå€¤ã®ã¾ã¾å‡ºåŠ› | âœ… RobustScaleré©ç”¨ |
| **ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–** | âŒ DataFrameå½¢å¼ | âœ… TFåˆ¥ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç”Ÿæˆ |
| **å“è³ªãƒ•ã‚£ãƒ«ã‚¿** | âŒ å…¨ç‰¹å¾´é‡å‡ºåŠ› | âœ… NaN/ç›¸é–¢/åˆ†æ•£é™¤å¤– |

---

## ğŸ“Š å‡¦ç†è©³ç´°

### 1. å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°

```python
def filter_features(features: pd.DataFrame) -> pd.DataFrame:
    """
    å“è³ªåŸºæº–ã«æº€ãŸãªã„ç‰¹å¾´é‡ã‚’é™¤å¤–
    
    é™¤å¤–æ¡ä»¶:
    - NaN/Inf å«æœ‰ç‡ > 1%
    - IQR < 1e-6ï¼ˆå®šæ•°åˆ—ï¼‰
    - ä»–ç‰¹å¾´ã¨ã®ç›¸é–¢ |Ï| > 0.95
    """
    # NaN/Infé™¤å¤–
    nan_ratio = features.isna().sum() / len(features)
    features = features.loc[:, nan_ratio < 0.01]
    
    # å®šæ•°åˆ—é™¤å¤–
    from scipy.stats import iqr
    feature_iqr = features.apply(iqr)
    features = features.loc[:, feature_iqr >= 1e-6]
    
    # é«˜ç›¸é–¢ãƒšã‚¢é™¤å¤–ï¼ˆä¸Šä¸‰è§’èµ°æŸ»ï¼‰
    corr_matrix = features.corr().abs()
    upper_tri = corr_matrix.where(
        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)
    )
    to_drop = [col for col in upper_tri.columns 
               if any(upper_tri[col] > 0.95)]
    features = features.drop(columns=to_drop)
    
    return features
```

### 2. æ­£è¦åŒ–ï¼ˆRobustScalerï¼‰

```python
from sklearn.preprocessing import RobustScaler

def normalize_features(features: pd.DataFrame) -> Tuple[np.ndarray, dict]:
    """
    RobustScalerã§æ­£è¦åŒ–ï¼ˆå¤–ã‚Œå€¤è€æ€§ï¼‰
    
    Returns:
        normalized: æ­£è¦åŒ–å¾Œã®é…åˆ—
        params: é€†å¤‰æ›ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆcenter_, scale_ï¼‰
    """
    scaler = RobustScaler()
    normalized = scaler.fit_transform(features)
    
    params = {
        'center_': scaler.center_.tolist(),
        'scale_': scaler.scale_.tolist(),
        'feature_names': features.columns.tolist()
    }
    
    return normalized, params
```

### 3. ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–

```python
def create_sequences(
    features: np.ndarray,
    tf_configs: Dict[str, int]
) -> Dict[str, np.ndarray]:
    """
    TFåˆ¥ã«ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’ç”Ÿæˆ

    Args:
        features: (N, F) æ­£è¦åŒ–æ¸ˆã¿ç‰¹å¾´é‡
        tf_configs: {'M1': 480, 'M5': 288, ...} # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦é•·

    Returns:
        {'M1': (N-480, 480, F), 'M5': (N-288, 288, F), ...}
    """
    sequences = {}

    for tf_name, window_size in tf_configs.items():
        seq_list = []
        for i in range(len(features) - window_size):
            seq_list.append(features[i:i+window_size])
        sequences[tf_name] = np.array(seq_list)

    return sequences
```

#### TFåˆ¥ãƒã‚¹ã‚¯å‡¦ç†

**ç›®çš„**: TFé•·å·®ç•°ã«ã‚ˆã‚‹æš—é»™çš„forward fillã¨æƒ…å ±æ­ªã¿ï¼ˆé«˜æ™‚é–“è»¸ã¸ã®å‹¾é…é›†ä¸­ï¼‰ã‚’é˜²æ­¢ã™ã‚‹ã€‚

**å®Ÿè£…**: per-TF maskè¡Œåˆ— + æœ‰åŠ¹ç‡é–¾å€¤ï¼ˆmax_valid_ratio=0.95ï¼‰ã«ã‚ˆã‚‹å“è³ªç®¡ç†

```python
def create_sequences_with_mask(
    features_per_tf: Dict[str, pd.DataFrame],  # TFåˆ¥ç”Ÿãƒ‡ãƒ¼ã‚¿
    tf_configs: Dict[str, int],
    max_valid_ratio: float = 0.95,
    filled_weight_decay: float = 0.6
) -> Dict[str, Any]:
    """
    TFåˆ¥ãƒã‚¹ã‚¯å‡¦ç†ä»˜ãã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ

    Args:
        features_per_tf: {'M1': DataFrame(N_m1, F), 'M5': DataFrame(N_m5, F), ...}
        tf_configs: {'M1': 480, 'M5': 288, ...}
        max_valid_ratio: æ¬ æç‡é–¾å€¤ï¼ˆè¶…éæ™‚TFé™¤å¤–ï¼‰
        filled_weight_decay: forward fillå¾Œã®æå¤±é‡ã¿æ¸›è¡°ç‡

    Returns:
        {
            'sequences': {'M1': (N, 480, F), ...},
            'masks': {'M1': (N, 480), ...},  # 1=æœ‰åŠ¹, 0=æ¬ æ/filled
            'loss_weights': {'M1': (N, 480), ...},  # å­¦ç¿’é‡ã¿
            'tf_validity': {'M1': 0.98, ...},  # TFåˆ¥æœ‰åŠ¹ç‡
            'excluded_tfs': ['H4']  # é™¤å¤–ã•ã‚ŒãŸTF
        }
    """
    result = {
        'sequences': {},
        'masks': {},
        'loss_weights': {},
        'tf_validity': {},
        'excluded_tfs': []
    }

    for tf_name, window_size in tf_configs.items():
        if tf_name not in features_per_tf:
            continue

        df = features_per_tf[tf_name]
        N = len(df)

        # æ¬ æãƒ•ãƒ©ã‚°ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ï¼‰
        is_missing = df.isna().any(axis=1).values  # (N,)

        # Forward fillé©ç”¨
        df_filled = df.fillna(method='ffill')

        # filled ãƒ•ãƒ©ã‚°
        was_filled = is_missing & ~df_filled.isna().any(axis=1).values

        # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–
        seq_list = []
        mask_list = []
        weight_list = []

        for i in range(N - window_size):
            window = df_filled.iloc[i:i+window_size].values  # (window, F)
            seq_list.append(window)

            # ãƒã‚¹ã‚¯ç”Ÿæˆï¼ˆæ¬ æ+filledç®‡æ‰€ã‚’0ï¼‰
            window_missing = is_missing[i:i+window_size]
            window_filled = was_filled[i:i+window_size]
            mask = ~(window_missing | window_filled)  # æœ‰åŠ¹=True
            mask_list.append(mask.astype(float))

            # æå¤±é‡ã¿ç”Ÿæˆ
            weight = np.ones(window_size, dtype=float)
            weight[window_filled] = filled_weight_decay  # filledç®‡æ‰€ã‚’æ¸›è¡°
            weight_list.append(weight)

        sequences = np.array(seq_list)  # (N, window, F)
        masks = np.array(mask_list)  # (N, window)
        weights = np.array(weight_list)  # (N, window)

        # TFåˆ¥æœ‰åŠ¹ç‡è¨ˆç®—
        valid_ratio = masks.mean()

        # é–¾å€¤ãƒã‚§ãƒƒã‚¯
        if valid_ratio < (1.0 - max_valid_ratio):
            logger.warning(
                f"TF {tf_name} é™¤å¤–: æœ‰åŠ¹ç‡={valid_ratio:.3f} < {1.0-max_valid_ratio:.3f}"
            )
            result['excluded_tfs'].append(tf_name)
            continue

        result['sequences'][tf_name] = sequences
        result['masks'][tf_name] = masks
        result['loss_weights'][tf_name] = weights
        result['tf_validity'][tf_name] = valid_ratio

    return result
```

**æ•´åˆ—å›³**:
```
TFåˆ¥ãƒ‡ãƒ¼ã‚¿æ•´åˆ—ï¼ˆæ¬ æå·®ç•°ã®å¯è¦–åŒ–ï¼‰

M1:  [â– â– â– â– â– â– â– â– â– â–¡â–¡â– â– â– â– â– â– â– â– â– ]  â† æ¬ æ2ç®‡æ‰€ï¼ˆâ–¡ï¼‰
M5:  [â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– ]  â† æ¬ æãªã—
H1:  [â– â– â–¡â–¡â–¡â– â– â– â– â– â– â– â– â– â– â– â– â– â– â– ]  â† æ¬ æ3ç®‡æ‰€
H4:  [â–¡â–¡â–¡â–¡â–¡â–¡â– â– â– â– â– â– â– â– â– â– â– â– â– â– ]  â† æ¬ æ6ç®‡æ‰€ï¼ˆé™¤å¤–å€™è£œï¼‰

maské©ç”¨å¾Œ:
M1:  [1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1]
M5:  [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
H1:  [1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
H4:  [0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1]  â† æœ‰åŠ¹ç‡60% â†’ é™¤å¤–

loss_weighté©ç”¨:
M1:  [1.0 1.0 ... 0.6 0.6 1.0 ...]  â† filledç®‡æ‰€ã¯0.6
```

**æˆåŠŸæŒ‡æ¨™**:
- ç„¡åŠ¹TFé™¤å¤–ç‡ < 5%
- æ¬ æè£œå®Œãƒãƒ¼å­¦ç¿’é‡ã¿ â‰¤ 0.6
- è£œå®Œã‚µãƒ³ãƒ—ãƒ«ã®æœŸå¾…å€¤èª¤å·® |Î”| < 0.3pips

**æ¤œè¨¼**:
```python
def test_tf_mask_processing():
    """TFåˆ¥ãƒã‚¹ã‚¯å‡¦ç†ã®æ¤œè¨¼"""
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆM5ã«æ¬ æãªã—ã€H4ã«40%æ¬ æï¼‰
    features_per_tf = {
        'M5': pd.DataFrame(np.random.randn(1000, 50)),
        'H4': pd.DataFrame(np.random.randn(1000, 50))
    }
    # H4ã«æ¬ ææ³¨å…¥
    features_per_tf['H4'].iloc[:400] = np.nan

    result = create_sequences_with_mask(
        features_per_tf,
        tf_configs={'M5': 288, 'H4': 48},
        max_valid_ratio=0.95
    )

    # H4ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
    assert 'H4' in result['excluded_tfs'], "H4ãŒé™¤å¤–ã•ã‚Œã‚‹ã¹ã"
    assert 'M5' in result['sequences'], "M5ã¯æ®‹ã‚‹ã¹ã"

    # M5ã®æœ‰åŠ¹ç‡ç¢ºèª
    assert result['tf_validity']['M5'] > 0.95, "M5æœ‰åŠ¹ç‡ãŒé«˜ã„ã¹ã"
```

#### æ¬ æè£œå®Œæ™‚ã®å­¦ç¿’é‡ã¿æ¸›è¡°

**ç›®çš„**: forward fillè£œå®Œã«ã‚ˆã‚‹æ–¹å‘ç¢ºç‡éä¿¡ï¼ˆconfidenceéå¤§ï¼‰ã‚’é˜²æ­¢ã™ã‚‹ã€‚

**å®Ÿè£…**: filled_flagä»˜ä¸ â†’ loss_weightæŒ‡æ•°æ¸›è¡°ï¼ˆé€£ç¶šè£œå®Œæ™‚ï¼‰ â†’ å“è³ªãƒ­ã‚°å‡ºåŠ›

```python
def compute_filled_loss_weights(
    filled_flags: np.ndarray,  # (N, window) bool
    base_weight: float = 1.0,
    decay_per_consecutive: float = 0.9,
    min_weight: float = 0.3
) -> np.ndarray:
    """
    é€£ç¶šæ¬ æè£œå®Œã«å¯¾ã™ã‚‹æŒ‡æ•°æ¸›è¡°é‡ã¿è¨ˆç®—

    Args:
        filled_flags: filledç®‡æ‰€ã®ãƒ•ãƒ©ã‚° (True=filled)
        base_weight: åŸºæœ¬é‡ã¿
        decay_per_consecutive: é€£ç¶šã”ã¨ã®æ¸›è¡°ç‡ï¼ˆä¾‹: 0.9^kï¼‰
        min_weight: æœ€å°é‡ã¿

    Returns:
        loss_weights: (N, window) å­¦ç¿’é‡ã¿
    """
    N, window = filled_flags.shape
    weights = np.full((N, window), base_weight, dtype=float)

    for i in range(N):
        consecutive_count = 0
        for j in range(window):
            if filled_flags[i, j]:
                consecutive_count += 1
                # æŒ‡æ•°æ¸›è¡°: base_weight * (decay^k)
                decay_factor = decay_per_consecutive ** consecutive_count
                weights[i, j] = max(base_weight * decay_factor, min_weight)
            else:
                consecutive_count = 0  # ãƒªã‚»ãƒƒãƒˆ

    return weights


# å“è³ªãƒ­ã‚°å‡ºåŠ›
class FilledDataQualityLogger:
    """è£œå®Œãƒ‡ãƒ¼ã‚¿ã®å“è³ªç›£è¦–"""

    def __init__(self):
        self.filled_ratios = []
        self.expectancy_errors = []

    def log_batch(self, filled_flags, predictions, targets):
        """
        ãƒãƒƒãƒã”ã¨ã®è£œå®Œãƒ‡ãƒ¼ã‚¿å“è³ªã‚’è¨˜éŒ²

        Args:
            filled_flags: (batch, seq) bool
            predictions: (batch,) predicted values
            targets: (batch,) true values
        """
        # è£œå®Œç‡
        filled_ratio = filled_flags.sum() / filled_flags.size
        self.filled_ratios.append(filled_ratio)

        # filledç®‡æ‰€ã®æœŸå¾…å€¤èª¤å·®
        filled_mask = filled_flags.any(axis=1)  # ãƒãƒƒãƒãƒ¬ãƒ™ãƒ«
        if filled_mask.sum() > 0:
            filled_preds = predictions[filled_mask]
            filled_targets = targets[filled_mask]
            error = np.abs(filled_preds - filled_targets).mean()
            self.expectancy_errors.append(error)

    def check_quality_kpi(self):
        """KPIé”æˆç¢ºèª"""
        mean_error = np.mean(self.expectancy_errors)

        if mean_error > 0.3:  # 0.3pipsé–¾å€¤
            logger.warning(
                f"è£œå®Œã‚µãƒ³ãƒ—ãƒ«æœŸå¾…å€¤èª¤å·®è¶…é: {mean_error:.4f} pips > 0.3 pips"
            )
            return False

        return True


# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—å†…
quality_logger = FilledDataQualityLogger()

for batch in dataloader:
    sequences, masks, filled_flags = batch['sequences'], batch['masks'], batch['filled']

    # é‡ã¿è¨ˆç®—
    loss_weights = compute_filled_loss_weights(filled_flags)

    # äºˆæ¸¬
    predictions = model(sequences, masks)

    # æå¤±è¨ˆç®—ï¼ˆé‡ã¿é©ç”¨ï¼‰
    loss = weighted_loss(predictions, targets, loss_weights)

    # å“è³ªãƒ­ã‚°
    quality_logger.log_batch(filled_flags, predictions.detach(), targets)

# ã‚¨ãƒãƒƒã‚¯çµ‚äº†æ™‚
quality_logger.check_quality_kpi()
```

**æˆåŠŸæŒ‡æ¨™**:
- è£œå®Œã‚µãƒ³ãƒ—ãƒ«ã®æœŸå¾…å€¤èª¤å·® |Î”| < 0.3pips
- é€£ç¶šè£œå®Œ3å›ä»¥ä¸Šã®ç®‡æ‰€: é‡ã¿ â‰¤ 0.5

**æ¤œè¨¼**:
```python
def test_filled_weight_decay():
    """é€£ç¶šè£œå®Œã®é‡ã¿æ¸›è¡°ã‚’æ¤œè¨¼"""
    # é€£ç¶š3ç®‡æ‰€filled
    filled_flags = np.array([[False, True, True, True, False, False]])

    weights = compute_filled_loss_weights(
        filled_flags,
        base_weight=1.0,
        decay_per_consecutive=0.9,
        min_weight=0.3
    )

    # é€£ç¶š1å›ç›®: 1.0 * 0.9 = 0.9
    # é€£ç¶š2å›ç›®: 1.0 * 0.9^2 = 0.81
    # é€£ç¶š3å›ç›®: 1.0 * 0.9^3 = 0.729
    assert abs(weights[0, 1] - 0.9) < 0.01
    assert abs(weights[0, 2] - 0.81) < 0.01
    assert abs(weights[0, 3] - 0.729) < 0.01
    assert weights[0, 0] == 1.0
    assert weights[0, 4] == 1.0
```

### 4. æœªæ¥ãƒªãƒ¼ã‚¯æ¤œæŸ»

```python
def check_future_leak(
    sequences: Dict[str, np.ndarray],
    timestamps: np.ndarray,
    target_times: np.ndarray
) -> bool:
    """
    ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å†…ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ™‚åˆ»ã‚ˆã‚Šæœªæ¥ã®ãƒ‡ãƒ¼ã‚¿ãŒæ··å…¥ã—ã¦ã„ãªã„ã‹ç¢ºèª
    
    Returns:
        True: ãƒªãƒ¼ã‚¯ãªã—
        False: ãƒªãƒ¼ã‚¯æ¤œå‡º
    """
    for tf_name, seq in sequences.items():
        seq_end_times = timestamps[len(timestamps) - len(seq):]
        
        # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æœ€çµ‚æ™‚åˆ» < ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ™‚åˆ»
        if not all(seq_end_times < target_times[:len(seq_end_times)]):
            logger.error(f"æœªæ¥ãƒªãƒ¼ã‚¯æ¤œå‡º: {tf_name}")
            return False
    
    return True
```

---

## ğŸ“Š HDF5ã‚¹ã‚­ãƒ¼ãƒ

### å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: `models/*_preprocessed.h5`

```python
with h5py.File('preprocessed.h5', 'w') as f:
    # TFåˆ¥ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰
    sequences_group = f.create_group('sequences')
    sequences_group.create_dataset('M1', data=seq_M1, dtype='float32')
    sequences_group.create_dataset('M5', data=seq_M5, dtype='float32')
    sequences_group.create_dataset('M15', data=seq_M15, dtype='float32')
    sequences_group.create_dataset('H1', data=seq_H1, dtype='float32')
    sequences_group.create_dataset('H4', data=seq_H4, dtype='float32')
    
    # æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆJSONï¼‰
    f.create_dataset('scaler_params',
                     data=json.dumps(scaler_params).encode())
    
    # æœ€çµ‚ç‰¹å¾´é‡å
    f.create_dataset('feature_names',
                     data=[name.encode() for name in feature_names])
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    f.create_dataset('metadata',
                     data=json.dumps({
                         'input_features': 60,
                         'filtered_features': 52,
                         'nan_filtered': 3,
                         'const_filtered': 2,
                         'corr_filtered': 3,
                         'sequence_lengths': {
                             'M1': 480, 'M5': 288, 'M15': 192,
                             'H1': 96, 'H4': 48
                         },
                         'future_leak_check': 'PASS',
                         'timestamp': '2025-10-22T12:00:00Z'
                     }).encode())
```

---

## å“è³ªçµ±è¨ˆ

ãƒ­ã‚°å‡ºåŠ›ä¾‹:
```
ğŸ“‚ ç¬¬2æ®µéšç‰¹å¾´é‡èª­è¾¼: 60åˆ—
ğŸ” å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°:
   - NaNé™¤å¤–: 3åˆ—
   - å®šæ•°åˆ—é™¤å¤–: 2åˆ—
   - é«˜ç›¸é–¢é™¤å¤–: 3åˆ—
   â†’ æœ€çµ‚ç‰¹å¾´é‡: 52åˆ—

âš™ï¸ æ­£è¦åŒ–: RobustScaleré©ç”¨
   - centerç¯„å›²: [-0.05, 0.08]
   - scaleç¯„å›²: [0.3, 2.1]

ğŸ“Š ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–:
   - M1: (45000, 480, 52)
   - M5: (45000, 288, 52)
   - M15: (45000, 192, 52)
   - H1: (45000, 96, 52)
   - H4: (45000, 48, 52)

âœ… æœªæ¥ãƒªãƒ¼ã‚¯æ¤œæŸ»: PASS
   å‡ºåŠ›: models/fx_mtf_20251022_120000_preprocessed.h5
```

---

## ğŸš¨ ã‚¨ãƒ©ãƒ¼æ¡ä»¶

| æ¡ä»¶ | é–¾å€¤ | å¯¾å¿œ |
|------|------|------|
| NaN/Inf å«æœ‰ç‡ | >1% | ã‚¨ãƒ©ãƒ¼çµ‚äº†ï¼ˆç¬¬2æ®µéšç¢ºèªï¼‰ |
| ãƒ•ã‚£ãƒ«ã‚¿å¾Œç‰¹å¾´é‡æ•° | <30åˆ— | è­¦å‘Šï¼ˆç¬¬2æ®µéšã§ç‰¹å¾´è¿½åŠ æ¤œè¨ï¼‰ |
| æœªæ¥ãƒªãƒ¼ã‚¯æ¤œå‡º | 1ä»¶ã§ã‚‚ | ã‚¨ãƒ©ãƒ¼çµ‚äº† |
| ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆå¤±æ•— | æ™‚ç³»åˆ—ä¸æ•´åˆ | ã‚¨ãƒ©ãƒ¼çµ‚äº†ï¼ˆç¬¬1æ®µéšç¢ºèªï¼‰ |
| æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç•°å¸¸ | center/scale NaN | ã‚¨ãƒ©ãƒ¼çµ‚äº† |

---

## ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ«å | å†…å®¹ | Gitç®¡ç† |
|-----------|------|---------|
| `data/preprocessor.h5` | æ­£è¦åŒ–æ¸ˆã¿ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ | âŒ é™¤å¤– |
| `data/preprocessor_report.json` | æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ»å“è³ªçµ±è¨ˆ | âŒ é™¤å¤– |
| `data/preprocessor_report.md` | äººé–“å¯èª­ãƒ¬ãƒãƒ¼ãƒˆ | âŒ é™¤å¤– |

**ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯ `YYYYMMDD_HHMMSS_preprocessor.<ext>` ã«ãƒªãƒãƒ¼ãƒ  (JST)

ä¾‹: `20251024_143500_preprocessor.h5`

---

## ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

### JSONãƒ¬ãƒãƒ¼ãƒˆ (`data/preprocessor_report.json`)

æ¬¡å‡¦ç†ï¼ˆå­¦ç¿’ï¼‰ãŒèª­ã¿è¾¼ã‚€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æƒ…å ±:

```json
{
  "timestamp": "2025-10-24T14:35:15+09:00",
  "process": "preprocessor",
  "version": "1.0",
  "input": {
    "file": "data/feature_calculator.h5",
    "source_report": "data/feature_calculator_report.json",
    "features": 66,
    "samples": 2500000
  },
  "output": {
    "file": "data/preprocessor.h5",
    "size_mb": 350
  },
  "filtering": {
    "original_features": 66,
    "removed_nan": 2,
    "removed_constant": 1,
    "removed_correlation": 3,
    "final_features": 60,
    "removed_columns": ["col_A", "col_B", "col_C", "col_D", "col_E", "col_F"]
  },
  "normalization": {
    "method": "RobustScaler",
    "scaler_params": {
      "feature_1": {"center": 0.0015, "scale": 0.0023},
      "feature_2": {"center": 0.0008, "scale": 0.0019},
      "...": "60 features total"
    }
  },
  "sequences": {
    "window_size": 360,
    "stride": 1,
    "total_sequences": 2499640,
    "valid_sequences": 2499500,
    "dropped_sequences": 140
  },
  "quality": {
    "avg_quality_score": 0.92,
    "low_quality_sequences": 124975,
    "low_quality_ratio": 0.05,
    "future_leak_check": "passed",
    "monotonic_check": "passed"
  },
  "performance": {
    "execution_time_sec": 45,
    "memory_peak_mb": 8000
  }
}
```

### Markdownãƒ¬ãƒãƒ¼ãƒˆ (`data/preprocessor_report.md`)

äººé–“ã«ã‚ˆã‚‹æ¤œè¨¼ç”¨ã®å¯èª­ãƒ¬ãƒãƒ¼ãƒˆ:

```markdown
# å‰å‡¦ç† å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ

**å®Ÿè¡Œæ—¥æ™‚**: 2025-10-24 14:35:15 JST  
**å‡¦ç†æ™‚é–“**: 45ç§’  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0

## ğŸ“Š å…¥åŠ›

- **å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«**: `data/feature_calculator.h5`
- **ç‰¹å¾´é‡æ•°**: 66åˆ—
- **ã‚µãƒ³ãƒ—ãƒ«æ•°**: 2,500,000

## ğŸ¯ å‡¦ç†çµæœ

- **å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«**: `data/preprocessor.h5`
- **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: 350 MB
- **æœ€çµ‚ç‰¹å¾´é‡æ•°**: 60åˆ—
- **ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°**: 2,499,500

### ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœ

| é …ç›® | é™¤å¤–æ•° | æ®‹å­˜æ•° |
|-----|--------|--------|
| å…ƒã®ç‰¹å¾´é‡ | - | 66 |
| NaNåˆ—é™¤å¤– | 2 | 64 |
| å®šæ•°åˆ—é™¤å¤– | 1 | 63 |
| é«˜ç›¸é–¢é™¤å¤– | 3 | 60 |

**é™¤å¤–ã•ã‚ŒãŸåˆ—**: col_A, col_B, col_C, col_D, col_E, col_F

### æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

**æ‰‹æ³•**: RobustScaler (IQRåŸºæº–)

æ­£è¦åŒ–ä¾‹ (æœ€åˆã®5ç‰¹å¾´é‡):

| ç‰¹å¾´é‡å | Center | Scale |
|---------|--------|-------|
| M1_price_change_pips | 0.0015 | 0.0023 |
| M5_price_change_pips | 0.0008 | 0.0019 |
| M15_price_change_pips | 0.0012 | 0.0021 |
| spread_pips | 0.0005 | 0.0003 |
| tick_volume | 1200.0 | 850.5 |

### ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ

| é …ç›® | å€¤ |
|-----|-----|
| ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º | 360 (6æ™‚é–“) |
| ã‚¹ãƒˆãƒ©ã‚¤ãƒ‰ | 1 |
| ç·ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ | 2,499,640 |
| æœ‰åŠ¹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ | 2,499,500 |
| é™¤å¤–ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ | 140 (0.006%) |

## ğŸ“ˆ å“è³ªçµ±è¨ˆ

| é …ç›® | å€¤ |
|-----|-----|
| å¹³å‡å“è³ªã‚¹ã‚³ã‚¢ | 0.92 |
| ä½å“è³ªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ | 124,975 (5.0%) |
| æœªæ¥ãƒªãƒ¼ã‚¯ãƒã‚§ãƒƒã‚¯ | âœ… åˆæ ¼ |
| å˜èª¿æ€§ãƒã‚§ãƒƒã‚¯ | âœ… åˆæ ¼ |

## âš™ï¸ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

- **å®Ÿè¡Œæ™‚é–“**: 45ç§’
- **ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª**: 8,000 MB

## âš ï¸ è­¦å‘Šãƒ»æ³¨æ„äº‹é …

- 6åˆ—ã‚’å“è³ªãƒ•ã‚£ãƒ«ã‚¿ã§é™¤å¤–ï¼ˆNaNã€å®šæ•°ã€é«˜ç›¸é–¢ï¼‰
- ä½å“è³ªã‚·ãƒ¼ã‚±ãƒ³ã‚¹5.0%ï¼ˆãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç•°å¸¸æœŸé–“ï¼‰
- 140ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’é™¤å¤–ï¼ˆNaNå«æœ‰ï¼‰

## âœ… æ¤œè¨¼çµæœ

- âœ… å…¨ç‰¹å¾´é‡ã®æ­£è¦åŒ–å®Œäº†
- âœ… æœªæ¥ãƒªãƒ¼ã‚¯ãªã—
- âœ… æ™‚ç³»åˆ—ã®å˜èª¿æ€§ç¢ºèª
- âœ… æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜å®Œäº†
```

---

## ğŸ“ ãƒ­ã‚°å‡ºåŠ›

### æ™‚åˆ»è¡¨ç¤ºãƒ«ãƒ¼ãƒ«
- **å…¨ãƒ­ã‚°**: æ—¥æœ¬æ™‚é–“(JST)ã§è¡¨ç¤º
- **ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: `YYYY-MM-DD HH:MM:SS JST`
- **ãƒ‡ãƒ¼ã‚¿æœŸé–“**: æ—¥æœ¬æ™‚é–“ã§æ˜è¨˜
- **è©³ç´°**: [TIMEZONE_UTILS_SPEC.md](./utils/TIMEZONE_UTILS_SPEC.md)

### å‡ºåŠ›ä¾‹
```
ğŸ”„ ç¬¬3æ®µéš: å‰å‡¦ç†é–‹å§‹ [2025-10-23 23:50:30 JST]
ğŸ“‚ å…¥åŠ›: models/fx_mtf_20251022_100000_features.h5
   æœŸé–“: 2024-01-01 00:00:00 JST ï½ 2024-12-31 23:59:00 JST
   ç‰¹å¾´é‡: 58åˆ—

ğŸ” å…¥åŠ›å“è³ªã‚¹ã‚³ã‚¢è¨ˆç®—
   å¹³å‡ã‚¹ã‚³ã‚¢: 0.92, ä½å“è³ªã‚·ãƒ¼ã‚±ãƒ³ã‚¹: 5%

ğŸ§¹ å“è³ªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
   NaNé™¤å¤–: 2åˆ—, å®šæ•°åˆ—é™¤å¤–: 1åˆ—, é«˜ç›¸é–¢é™¤å¤–: 3åˆ—
   æ®‹å­˜ç‰¹å¾´é‡: 52åˆ—

ğŸ“Š æ­£è¦åŒ–å®Ÿæ–½
   RobustScaleré©ç”¨å®Œäº†

âœ… å‰å‡¦ç†å®Œäº† [2025-10-23 23:51:15 JST]
   å‡ºåŠ›: models/fx_mtf_20251022_100000_preprocessed.h5
```

---

## âš™ï¸ è¨­å®šä¾‹

```yaml
# config/preprocessing.yaml
preprocessing:
  # å“è³ªãƒ•ã‚£ãƒ«ã‚¿
  quality_filter:
    max_nan_ratio: 0.01          # 1%
    min_iqr: 1.0e-6              # å®šæ•°åˆ—é–¾å€¤
    max_correlation: 0.95         # é«˜ç›¸é–¢é–¾å€¤
  
  # æ­£è¦åŒ–
  normalization:
    method: robust                # robust | standard | minmax
    quantile_range: [25, 75]     # RobustScalerç”¨
  
  # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–
  sequences:
    M1: 480   # 8æ™‚é–“
    M5: 288   # 24æ™‚é–“
    M15: 192  # 48æ™‚é–“
    H1: 96    # 4æ—¥
    H4: 48    # 8æ—¥
  
  # æœªæ¥ãƒªãƒ¼ã‚¯æ¤œæŸ»
  leak_check:
    enabled: true
    strict_mode: true
  
  # ã‚¨ãƒ©ãƒ¼é–¾å€¤
  thresholds:
    min_features_after_filter: 30
```

---

## ğŸ”— é–¢é€£ä»•æ§˜æ›¸

- **å‰æ®µéš**:
  - ç¬¬1æ®µéš: [DATA_COLLECTOR_SPEC.md](./DATA_COLLECTOR_SPEC.md) - ç”Ÿãƒ‡ãƒ¼ã‚¿åé›†
  - ç¬¬2æ®µéš: [FEATURE_CALCULATOR_SPEC.md](./FEATURE_CALCULATOR_SPEC.md) - ç‰¹å¾´é‡è¨ˆç®—
- **æ¬¡å·¥ç¨‹**: ç¬¬4æ®µéš: [TRAINER_SPEC.md](./TRAINER_SPEC.md) - å­¦ç¿’
- **å‚ç…§**:
  - [FUTURE_LEAK_PREVENTION_SPEC.md](./validator/FUTURE_LEAK_PREVENTION_SPEC.md) - æœªæ¥ãƒªãƒ¼ã‚¯æ¤œæŸ»è©³ç´°

---

## ğŸ“Œ æ³¨æ„äº‹é …

### å‡¦ç†æ®µéšåˆ†é›¢ã®é‡è¦æ€§

**æ—§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å¤±æ•—**: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å†…ã§ç‰¹å¾´é‡è¨ˆç®— â†’ è²¬ä»»ä¸æ˜ç¢ºãƒ»ãƒ‡ãƒãƒƒã‚°å›°é›£

**æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ”¹å–„**:
```
ç¬¬2æ®µéš: ç‰¹å¾´é‡è¨ˆç®—
  - å…¥åŠ›: raw_data.h5ï¼ˆOHLCVï¼‰
  - å‡¦ç†: RSI, MACD, ATR, TFé–“å·®åˆ†ç­‰
  - å‡ºåŠ›: features.h5ï¼ˆDataFrameå½¢å¼ï¼‰

ç¬¬3æ®µéš: å‰å‡¦ç†ï¼ˆæœ¬ä»•æ§˜æ›¸ï¼‰
  - å…¥åŠ›: features.h5ï¼ˆè¨ˆç®—æ¸ˆã¿ç‰¹å¾´é‡ï¼‰
  - å‡¦ç†: æ­£è¦åŒ–ãƒ»ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŒ–ãƒ»å“è³ªæ¤œè¨¼
  - å‡ºåŠ›: preprocessed.h5ï¼ˆå­¦ç¿’å¯èƒ½å½¢å¼ï¼‰
```

### å®Ÿè£…æ™‚ã®æ³¨æ„

1. **ç¬¬2æ®µéšã®è¨ˆç®—çµæœã‚’ä¿¡é ¼**: ç‰¹å¾´é‡ã®å†è¨ˆç®—ç¦æ­¢
2. **æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¿å­˜å¿…é ˆ**: æ¨è«–æ™‚ã®é€†å¤‰æ›ã«å¿…è¦
3. **ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã®å›ºå®š**: MULTI_TF_FUSION_SPEC.md ã®è¨­è¨ˆã«æº–æ‹ 
4. **æœªæ¥ãƒªãƒ¼ã‚¯æ¤œæŸ»ã¯å¿…é ˆ**: ã‚¨ãƒ©ãƒ¼æ™‚ã¯å³åº§ã«åœæ­¢

---

## ğŸ”® å°†æ¥æ‹¡å¼µ

### å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º1: åŸºæœ¬å®Ÿè£…ï¼ˆç¾åœ¨ï¼‰
- RobustScaleræ­£è¦åŒ–
- TFåˆ¥å›ºå®šã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
- åŸºæœ¬å“è³ªãƒ•ã‚£ãƒ«ã‚¿

### å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º2: æ‹¡å¼µæ©Ÿèƒ½
- ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆAugmentationï¼‰
  - ãƒã‚¤ã‚ºä»˜åŠ 
  - æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«å¤‰å‹•
- å‹•çš„ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
- ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°

### å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º3: æœ€é©åŒ–
- ä¸¦åˆ—ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç”Ÿæˆ
- ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼ˆlazy loadingï¼‰
- GPUæ­£è¦åŒ–ï¼ˆcupyçµ±åˆï¼‰

---


## ğŸ“š ã‚µãƒ–ä»•æ§˜æ›¸

è©³ç´°ãªå®Ÿè£…ä»•æ§˜ã¯ä»¥ä¸‹ã®ã‚µãƒ–ä»•æ§˜æ›¸ã‚’å‚ç…§ï¼š

### å…¥åŠ›å“è³ªç®¡ç†
- **[INPUT_QUALITY_SPEC.md](./preprocessor/INPUT_QUALITY_SPEC.md)** - å…¥åŠ›å“è³ªåŠ£åŒ–è¨­è¨ˆã€æ¬ æåˆ¤å®šã€ã‚®ãƒ£ãƒƒãƒ—é™¤å¤–

  **å†…å®¹**:
  - å…¥åŠ›å“è³ªã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹ä¿¡é ¼åº¦èª¿æ•´
  - ä¸»è¦åˆ—/è£œåŠ©åˆ—ã®æ¬ æåˆ†é›¢å‡¦ç†
  - é•·æœŸæ¬ æå¾Œã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åˆ†æ–­
  - é€£ç¶šã‚®ãƒ£ãƒƒãƒ—é™¤å¤–åŸºæº–

### ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§æ¤œè¨¼
- **[DATA_INTEGRITY_SPEC.md](./preprocessor/DATA_INTEGRITY_SPEC.md)** - åˆ—é †åºæ¤œè¨¼ã€TFãƒãƒƒãƒ”ãƒ³ã‚°

  **å†…å®¹**:
  - åˆ—é †åºãƒãƒƒã‚·ãƒ¥æ¤œè¨¼
  - TFãƒãƒƒãƒ”ãƒ³ã‚°å¤±æ•—æ™‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

### æ­£è¦åŒ–ä»•æ§˜
- **[NORMALIZATION_SPEC.md](./preprocessor/NORMALIZATION_SPEC.md)** - æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†

  **å†…å®¹**:
  - RobustScalerè©³ç´°ä»•æ§˜
  - æ­£è¦åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä¿å­˜ãƒ»ç®¡ç†

---

**æ›´æ–°å±¥æ­´**:
- 2025-10-22: ã‚µãƒ–ä»•æ§˜æ›¸ã«åˆ†é›¢ï¼ˆINPUT_QUALITY, DATA_INTEGRITY, NORMALIZATIONï¼‰
